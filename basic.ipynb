{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import os\n", "import autogen\n", "from autogen import ConversableAgent,AssistantAgent, UserProxyAgent"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## AGENTS\n", "\n", "it is an entity that can send and receive messages to and from other agents in environment which can be powered by models such as GPT-4, code excutors and humans\n", "\n", "![alt text](conversable-agent-58656a6f9b08b1d7d942a358e22a28bb.jpg)\n", "\n", "The agent has:\n", "\n", "1. list of LLM's\n", "2. code executor\n", "3. function and tool executor\n", "4. component for keeping human in loop"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["agent = ConversableAgent(\n", "    \"chatbot\",\n", "    llm_config={\"config_list\":[{\"model\":\"gpt-4\",\"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},   \n", "    code_execution_config=False, #To turn off code execution\n", "    function_map=None, #No functions registered\n", "    human_input_mode=\"NEVER\" #Never ask for human\n", ")"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke\",\"role\":\"user\"}])"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Sure, here is a light-hearted joke for you:\n", "\n", "Why don't scientists trust atoms?\n", "\n", "Because they make up everything!\n"]}], "source": ["print(reply)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Roles and Conversation\n", "\n", "we can assign roles to agents and make them participate in the conversation or chat with each other.\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["cathy=ConversableAgent(\n", "    \"cathy\",\n", "    system_message=\"You name is cathy and you are a part of a duo of autogen based model\", # defines the initial context of the agent\n", "    llm_config={\"config_list\":[{\"model\":\"gpt-4\",\"temperature\":0.9,\"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]}, # temperature is used for randomness of the model \n", "    human_input_mode=\"NEVER\",\n", ")\n", "adam=ConversableAgent(\n", "    \"adam\",\n", "    system_message=\"You name is cathy and you are a part of a duo of autogen based model\", # defines the initial context of the agent\n", "    llm_config={\"config_list\":[{\"model\":\"gpt-4\",\"temperature\":0.6,\"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]}, # temperature is used for randomness of the model \n", "    human_input_mode=\"NEVER\",\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# CHAT TERMINATION\n", "\n", "termination of chat is important because in any complex, autonomous workflows it is crrucial to stop the workflow "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Specify parameter in **intiate_chat** keyword :\n", "\n", "we define parameters when the conversation starts which determine when it should end\n", "\n", "`max_turn` : used to limit the number of turns \n", "\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33madam\u001b[0m (to cathy):\n", "\n", "Cathy, what is autogen\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to adam):\n", "\n", "Autogen is a tool used to simplify the creation and maintenance of programs that contain large amounts of repetitious text. It is especially valuable in programs that have several blocks of text that must be kept synchronized. \n", "\n", "In machine learning context, this term might be used to describe models or algorithms that can generate automatic responses, processes, or decisions based on the provided data. It's commonly associated with AI-based tools, including chatbots and digital assistants.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33madam\u001b[0m (to cathy):\n", "\n", "That's correct, Cathy. The autogen-based models are used in a variety of fields, including natural language processing, image recognition, and data analysis. They can learn from their mistakes, improve over time, and provide accurate results. Our duo is a good example of this, as we work together to understand and respond to user queries accurately and efficiently.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to adam):\n", "\n", "Absolutely, Adam. Our ability to analyze and interpret data given to us, learn from it, and produce appropriate responses is reflective of how versatile and dynamic autogen-based models can be. We make a great team in providing accurate, efficient, and sophisticated solutions and responses.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33madam\u001b[0m (to cathy):\n", "\n", "Absolutely, Cathy. Our combined capabilities allow us to provide a high level of service and sophistication in our responses. We can handle complex inquiries and provide detailed answers, which makes us a powerful tool for users who need quick and accurate information.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to adam):\n", "\n", "Definitely, Adam. The essence of our collaboration lies in the integration of our individual strengths. With your analytical prowess and my command over the language and communication, we can deliver comprehensive, accurate, and detailed responses. Moreover, we can continuously learn and improve our capabilities, which ensures our users get the best possible experience.\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["result = adam.initiate_chat(cathy, message=\"Cathy, what is autogen\",max_turns=3) #max_turn limits the conversation exchange to 3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Agent-triggered termination:\n", "\n", "we can also terminate a conversation using parameters to agent \n", "\n", "using `max_consecutive_auto_reply` : condition is triggered when the number of automatic responses to same sender exceeds a threshold"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["lim=ConversableAgent(\n", "    \"lim\",\n", "    system_message=\"your name is lim and you are a comedian\",\n", "    llm_config={\"config_list\":[{\"model\":\"gpt-4\",\"temperature\":1,\"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", "    max_consecutive_auto_reply=1,#limits the number of consecutive auto-replies\n", ")"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mlim\u001b[0m (to cathy):\n", "\n", "cathy tell me a joke\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to lim):\n", "\n", "Sure, here you go:\n", "\n", "Why don't scientists trust atoms?\n", "\n", "Because they make up everything!\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mlim\u001b[0m (to cathy):\n", "\n", "Oh that's a classic one, Cathy! Interested in science jokes, huh? Let me share one too:\n", "\n", "Why can't you trust an atom?\n", "\n", "Because they literally make up everything!\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to lim):\n", "\n", "That's a great one too, Lim! We both seem to enjoy a good atom joke.\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["result=lim.initiate_chat(cathy,message=\"cathy tell me a joke\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["using `is_terminated_msg` : a termination message is used to end the conversation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["raz=ConversableAgent(\n", "    \"raz\",\n", "    system_message=\"You name is raz and you are a comedian\",\n", "    llm_config={\"config_list\":[{\"model\":\"gpt-4\",\"temperature\":0.9,\"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]}, # temperature is used for randomness of the model \n", "    human_input_mode=\"NEVER\",\n", "    is_termination_msg=lambda msg:\"good bye\" in msg[\"content\"].lower(),\n", ")"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mlim\u001b[0m (to cathy):\n", "\n", "cathy tell me a joke and then say the words GOOD BYE.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to lim):\n", "\n", "Sure, here's a joke for you. Why don't scientists trust atoms? Because they make up everything! \n", "\n", "And now, GOOD BYE.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mlim\u001b[0m (to cathy):\n", "\n", "Thank you, Cathy! Remember, laughter is the best medicine! Have a great one. Goodbye!\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcathy\u001b[0m (to lim):\n", "\n", "You're absolutely right! Laughter is indeed the best medicine. I'm happy I could bring a smile to your face. Have a wonderful time! Goodbye!\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["result=lim.initiate_chat(cathy,message=\"cathy tell me a joke and then say the words GOOD BYE.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# ALLOWING HUMAN FEEDBACK IN AGENTS\n", "\n", "the human-in-the-loop components sits in front of auto reply components.\n", "\n", "![alt text](human-in-the-loop-56dc002683ab4481042ffd3d346d1759.png)\n", "\n", "the human-in-the-loop components can be customized through the `human_input_mode` parameter\n", "\n", "### Human input modes\n", "1. Never : no input from human\n", "2. Terminate : only requirs input from human if he decides to terminate or chooses to intercept and reply\n", "3. Always : human reply is always needed"]}, {"cell_type": "markdown", "metadata": {}, "source": ["using input mode = `Never`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "\n", "# Generate a random number between 1 and 100 (or any range you prefer)\n", "num = random.randint(1, 100)\n", "\n", "# Define the ConversableAgent\n", "agent_with_number = ConversableAgent(\n", "    \"agent_with_number\",\n", "    system_message=\"You are playing a game of guess-my-number. You have the \"\n", "                   f\"number {num} in your mind, and I will try to guess it. \"\n", "                   \"If I guess too high, say 'too high', if I guess too low, say 'too low'.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    is_termination_msg=lambda msg: \"53\" in msg[\"content\"],  # Terminate if the number is guessed\n", "    human_input_mode=\"NEVER\",  # Never ask for human input\n", ")"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["agent_guess_number = ConversableAgent(\n", "    \"agent_guess_number\",\n", "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n", "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n", "    \"you should guess a higher number. \",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result = agent_with_number.initiate_chat(\n", "    agent_guess_number,\n", "    message=\"I have a number between 1 and 100. Guess it!\",\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["using input mode = `Always`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["human_proxy = ConversableAgent(\n", "    \"human_proxy\",\n", "    llm_config=False,  # no LLM used for human proxy\n", "    human_input_mode=\"ALWAYS\",  # always ask for human input\n", ")\n", "\n", "# Start a chat with the agent with number with an initial guess.\n", "result = human_proxy.initiate_chat(\n", "    agent_with_number,  # this is the same agent with the number as before\n", "    message=\"35\",\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Code Executors"]}, {"cell_type": "markdown", "metadata": {}, "source": ["it is a component that takes input message, performs execution and output messages with results\n", "\n", "autogen provides 2 ways to execute code: \n", "1. command line code executor \n", "2. unix shell\n", "3. jupyter kernel"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["import tempfile\n", "\n", "from autogen import ConversableAgent\n", "from autogen.coding import LocalCommandLineCodeExecutor\n", "\n", "# Create a temporary directory to store the code files.\n", "temp_dir = tempfile.TemporaryDirectory()\n", "\n", "# Create a local command line code executor.\n", "executor = LocalCommandLineCodeExecutor(\n", "    timeout=10,  # Timeout for each code execution in seconds.\n", "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n", ")\n", "\n", "# Create an agent with code executor configuration.\n", "code_executor_agent = ConversableAgent(\n", "    \"code_executor_agent\",\n", "    llm_config=False,  # Turn off LLM for this agent.\n", "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n", "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n", ")"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[31m\n", ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[31m\n", ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n", "exitcode: 0 (execution succeeded)\n", "Code output: Scatter plot saved to scatter.png\n", "\n"]}], "source": ["message_with_code_block = \"\"\"This is a message with code block.\n", "The code block is below:\n", "```python\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "x = np.random.randint(0, 100, 100)\n", "y = np.random.randint(0, 100, 100)\n", "plt.scatter(x, y)\n", "plt.savefig('scatter.png')\n", "print('Scatter plot saved to scatter.png')\n", "```\n", "This is the end of the message.\n", "\"\"\"\n", "\n", "# Generate a reply for the given code.\n", "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n", "print(reply)"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['scatter.png', 'tmp_code_e24bf32d4a21990fb9e4b5eb889ebe5a.py']\n"]}], "source": ["print(os.listdir(temp_dir.name))"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["temp_dir.cleanup()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Docker Execution\n", "\n", "code : `autogen.coding.DockerCommandLineCodeExecutor`\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Local execution\n", "\n", "code : `autogen.coding.LocalCommandLineCodeExecutor`\n", "\n", "![alt text](code-executor-no-docker-0ec717a62637ff02e852efa284dd50d5.png)"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["from autogen.coding import DockerCommandLineCodeExecutor\n", "\n", "# Create a temporary directory to store the code files.\n", "temp_dir = tempfile.TemporaryDirectory()\n", "\n", "# Create a Docker command line code executor.\n", "executor = DockerCommandLineCodeExecutor(\n", "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n", "    timeout=10,  # Timeout for each code execution in seconds.\n", "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n", ")\n", "\n", "# Create an agent with code executor configuration that uses docker.\n", "code_executor_agent_using_docker = ConversableAgent(\n", "    \"code_executor_agent_docker\",\n", "    llm_config=False,  # Turn off LLM for this agent.\n", "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n", "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n", ")\n", "\n", "# When the code executor is no longer used, stop it to release the resources.\n", "# executor.stop()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Use code execution in conversation\n", "\n", "coding can be a conversation between a code writer agent and a code executor agent, mirroring the interaction between a programmer and a code interpreter.\n", "\n", "![alt text](code-execution-in-conversation-f02c7a3ea7e45e3f4aa71d8def851677.png)"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [], "source": ["# The code writer agent's system message is to instruct the LLM on how to use\n", "# the code executor in the code executor agent.\n", "code_writer_system_message = \"\"\"You are a helpful AI assistant.\n", "Solve tasks using your coding and language skills.\n", "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n", "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n", "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n", "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n", "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n", "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n", "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n", "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n", "Reply 'TERMINATE' in the end when everything is done.\n", "\"\"\"\n", "\n", "code_writer_agent = ConversableAgent(\n", "    \"code_writer_agent\",\n", "    system_message=code_writer_system_message,\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    code_execution_config=False,  # Turn off code execution for this agent.\n", ")"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mcode_executor_agent\u001b[0m (to code_writer_agent):\n", "\n", "Write Python code to calculate the 14th Fibonacci number.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent):\n", "\n", "Sure, let's use Python to calculate the Fibonacci sequence until the 14th number. Fibonacci sequence starts with 0 and 1 then each number is the sum of the two preceding ones.\n", "\n", "```python\n", "def fibonacci(n):\n", "    if n <= 0:\n", "        return None\n", "    elif n == 1:\n", "        return 0\n", "    elif n == 2:\n", "        return 1\n", "    else:\n", "        a, b = 0, 1\n", "        for _ in range(n-2):\n", "            a, b = b, a + b\n", "        return b\n", "\n", "print(fibonacci(14))\n", "```\n", "This Python script first creates the base cases for the Fibonacci series (where n=1 or n=2). For n above 2, it enters a loop in which each new Fibonacci number is calculated as the sum of the two preceding ones. It finally prints the 14th number in sequence.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mcode_executor_agent\u001b[0m (to code_writer_agent):\n", "\n", "5\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent):\n", "\n", "It appears there might be an off-by-one problem. The Fibonacci sequence starts from 0, so when you asked for the 14th number, it gave you the 13th one (index starts from 0). Let's adjust the indices and try again by inputting `15` instead of `14`.\n", "\n", "Here is the adjusted python code:\n", "\n", "```python\n", "def fibonacci(n):\n", "    if n <= 0:\n", "        return None\n", "    elif n == 1:\n", "        return 0\n", "    elif n == 2:\n", "        return 1\n", "    else:\n", "        a, b = 0, 1\n", "        for _ in range(n-2):\n", "            a, b = b, a + b\n", "        return b\n", "\n", "print(fibonacci(15))\n", "```\n", "\n", "This script should now return the 14th number in the actual Fibonacci sequence (0-indexed).\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["chat_result = code_executor_agent.initiate_chat(\n", "    code_writer_agent,\n", "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["to get the the stock price gains year-to-date for Tesla and Meta"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mcode_executor_agent\u001b[0m (to code_writer_agent):\n", "\n", "Today is 2024-12-10. Write Python code to plot TSLA's and META's stock price gains YTD, and save the plot to a file named 'stock_gains.png'.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent):\n", "\n", "Sure, we can use data from a financial API like Yahoo Finance to fetch the historical price data of the stocks. Python's `yfinance`, `matplotlib`, `datetime` and `pandas` libraries can be used to achieve that. If these libraries are not installed on your environment please install them using pip - `pip install yfinance matplotlib pandas`.\n", "\n", "Here's a Python script to plot the YTD gains for TSLA and META and save it as an image file:\n", "\n", "```python\n", "# filename: stock_price_plot.py\n", "\n", "import yfinance as yf\n", "import matplotlib.pyplot as plt\n", "from matplotlib.dates import DateFormatter\n", "import pandas as pd\n", "\n", "# Define the ticker symbols\n", "tickers = ['TSLA', 'META']\n", "\n", "# Define the date range\n", "end_date = pd.to_datetime('2024-12-10')\n", "start_date = pd.to_datetime('{}-01-01'.format(end_date.year))\n", "\n", "# Fetch the historical price data\n", "data = yf.download(tickers, start=start_date, end=end_date)\n", "\n", "# Calculate the daily returns\n", "data_pct_change = data['Adj Close'].pct_change().fillna(0)\n", "\n", "# Calculate the cumulative returns\n", "data_cum_returns = (1 + data_pct_change).cumprod()\n", "\n", "# Plot the YTD gains\n", "plt.figure(figsize=(10, 5))\n", "for ticker in tickers:\n", "    plt.plot(data_cum_returns.index, data_cum_returns[ticker], label=ticker)\n", "\n", "# Format the date on the x-axis\n", "date_format = DateFormatter(\"%b '%y\")\n", "ax = plt.gca()\n", "ax.xaxis.set_major_formatter(date_format)\n", "\n", "plt.xlabel('Date')\n", "plt.ylabel('Gains (YTD)')\n", "plt.title('TSLA and META Stock Price Gains YTD')\n", "plt.legend()\n", "plt.grid()\n", "plt.savefig('stock_gains.png')\n", "```\n", "\n", "Run the above script using Python: `python stock_price_plot.py`. This will create a line plot with Tesla and Meta's cumulative return throughout the year and this plot will be saved as 'stock_gains.png' in the same directory.\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["import datetime\n", "\n", "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n", "chat_result = code_executor_agent.initiate_chat(\n", "    code_writer_agent,\n", "    message=f\"Today is {today}. Write Python code to plot TSLA's and META's \"\n", "    \"stock price gains YTD, and save the plot to a file named 'stock_gains.png'.\",\n", ")"]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [{"ename": "TypeError", "evalue": "expected str, bytes or os.PathLike object, not TemporaryDirectory", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m Image(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstock_gains.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n", "File \u001b[1;32m<frozen ntpath>:108\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n", "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not TemporaryDirectory"]}], "source": ["from IPython.display import Image\n", "\n", "Image(os.path.join(temp_dir, \"stock_gains.png\"))"]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [], "source": ["temp_dir.cleanup()"]}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [], "source": ["executor.stop()  # Stop the docker command line code executor."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Tool use\n", "\n", "Tools are pre-defined functions that agents can use. \n", "\n", "Instead of writing arbitrary code, agents can call tools to perform actions, such as searching the web, performing calculations, reading files, or calling remote APIs."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Creating tools"]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": ["from typing import Annotated, Literal\n", "\n", "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n", "\n", "\n", "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n", "    if operator == \"+\":\n", "        return a + b\n", "    elif operator == \"-\":\n", "        return a - b\n", "    elif operator == \"*\":\n", "        return a * b\n", "    elif operator == \"/\":\n", "        return int(a / b)\n", "    else:\n", "        raise ValueError(\"Invalid operator\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Registering tools"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["<function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> int>"]}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": ["# Let's first define the assistant agent that suggests tool calls.\n", "assistant = ConversableAgent(\n", "    name=\"Assistant\",\n", "    system_message=\"You are a helpful AI assistant. \"\n", "    \"You can help with simple calculations. \"\n", "    \"Return 'TERMINATE' when the task is done.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")\n", "\n", "# The user proxy agent is used for interacting with the assistant agent\n", "# and executes tool calls.\n", "user_proxy = ConversableAgent(\n", "    name=\"User\",\n", "    llm_config=False,\n", "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "# Register the tool signature with the assistant agent.\n", "assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(calculator)\n", "\n", "# Register the tool function with the user proxy agent.\n", "user_proxy.register_for_execution(name=\"calculator\")(calculator)"]}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [], "source": ["from autogen import register_function\n", "\n", "# Register the calculator function to the two agents.\n", "register_function(\n", "    calculator,\n", "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n", "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n", "    name=\"calculator\",  # By default, the function name is used as the tool name.\n", "    description=\"A simple calculator\",  # A description of the tool.\n", ")"]}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "What is (44232 + 13312 / (232 - 32)) * 5?\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_mlHgcKOf5R389CkCaGn0ZTC3): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"a\": 232,\n", "  \"b\": 32,\n", "  \"operator\": \"-\"\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_mlHgcKOf5R389CkCaGn0ZTC3) *****\u001b[0m\n", "200\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_RAic0OyfnYP24CFw88hnZwdQ): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"a\": 13312,\n", "  \"b\": 200,\n", "  \"operator\": \"/\"\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_RAic0OyfnYP24CFw88hnZwdQ) *****\u001b[0m\n", "66\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_IA5HmV9hZ0Oz5osavnqSHZd2): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"a\": 44232,\n", "  \"b\": 66,\n", "  \"operator\": \"+\"\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_IA5HmV9hZ0Oz5osavnqSHZd2) *****\u001b[0m\n", "44298\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_RHCzrUF4DuR1b3yhfO126KUQ): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"a\": 44298,\n", "  \"b\": 5,\n", "  \"operator\": \"*\"\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_RHCzrUF4DuR1b3yhfO126KUQ) *****\u001b[0m\n", "221490\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "The result is 221490. TERMINATE\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["chat_result = user_proxy.initiate_chat(assistant, message=\"What is (44232 + 13312 / (232 - 32)) * 5?\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Tool Schema"]}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [{"data": {"text/plain": ["[{'type': 'function',\n", "  'function': {'description': 'A simple calculator',\n", "   'name': 'calculator',\n", "   'parameters': {'type': 'object',\n", "    'properties': {'a': {'type': 'integer', 'description': 'a'},\n", "     'b': {'type': 'integer', 'description': 'b'},\n", "     'operator': {'enum': ['+', '-', '*', '/'],\n", "      'type': 'string',\n", "      'description': 'operator'}},\n", "    'required': ['a', 'b', 'operator']}}}]"]}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": ["assistant.llm_config[\"tools\"]"]}, {"cell_type": "code", "execution_count": 42, "metadata": {}, "outputs": [], "source": ["from pydantic import BaseModel, Field\n", "\n", "\n", "class CalculatorInput(BaseModel):\n", "    a: Annotated[int, Field(description=\"The first number.\")]\n", "    b: Annotated[int, Field(description=\"The second number.\")]\n", "    operator: Annotated[Operator, Field(description=\"The operator.\")]\n", "\n", "\n", "def calculator(input: Annotated[CalculatorInput, \"Input to the calculator.\"]) -> int:\n", "    if input.operator == \"+\":\n", "        return input.a + input.b\n", "    elif input.operator == \"-\":\n", "        return input.a - input.b\n", "    elif input.operator == \"*\":\n", "        return input.a * input.b\n", "    elif input.operator == \"/\":\n", "        return int(input.a / input.b)\n", "    else:\n", "        raise ValueError(\"Invalid operator\")"]}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"data": {"text/plain": ["<function __main__.calculator(input: typing.Annotated[__main__.CalculatorInput, 'Input to the calculator.']) -> int>"]}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": ["assistant.register_for_llm(name=\"calculator\", description=\"A calculator tool that accepts nested expression as input\")(\n", "    calculator\n", ")\n", "user_proxy.register_for_execution(name=\"calculator\")(calculator)"]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"data": {"text/plain": ["[{'type': 'function',\n", "  'function': {'description': 'A calculator tool that accepts nested expression as input',\n", "   'name': 'calculator',\n", "   'parameters': {'type': 'object',\n", "    'properties': {'input': {'properties': {'a': {'description': 'The first number.',\n", "        'title': 'A',\n", "        'type': 'integer'},\n", "       'b': {'description': 'The second number.',\n", "        'title': 'B',\n", "        'type': 'integer'},\n", "       'operator': {'description': 'The operator.',\n", "        'enum': ['+', '-', '*', '/'],\n", "        'title': 'Operator',\n", "        'type': 'string'}},\n", "      'required': ['a', 'b', 'operator'],\n", "      'title': 'CalculatorInput',\n", "      'type': 'object',\n", "      'description': 'Input to the calculator.'}},\n", "    'required': ['input']}}}]"]}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": ["assistant.llm_config[\"tools\"]"]}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "What is (1423 - 123) / 3 + (32 + 23) * 5?\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_bwHXKTFjtw0HydrDwTtZd6oD): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"input\": {\n", "    \"a\": 1423,\n", "    \"b\": 123,\n", "    \"operator\": \"-\"\n", "  }\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_bwHXKTFjtw0HydrDwTtZd6oD) *****\u001b[0m\n", "1300\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_VwaNDDfafz0ln1p48DpfWhsw): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"input\": {\n", "    \"a\": 1300,\n", "    \"b\": 3,\n", "    \"operator\": \"/\"\n", "  }\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_VwaNDDfafz0ln1p48DpfWhsw) *****\u001b[0m\n", "433\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_0413ZuajTbtXcMwgCPxGzBEK): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"input\": {\n", "    \"a\": 32,\n", "    \"b\": 23,\n", "    \"operator\": \"+\"\n", "  }\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_0413ZuajTbtXcMwgCPxGzBEK) *****\u001b[0m\n", "55\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_UbxlutFyIusfFSM5Ja45xcln): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"input\": {\n", "    \"a\": 55,\n", "    \"b\": 5,\n", "    \"operator\": \"*\"\n", "  }\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_UbxlutFyIusfFSM5Ja45xcln) *****\u001b[0m\n", "275\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "\u001b[32m***** Suggested tool call (call_Gpm1UFMeWMJdSjxi2p7A19qi): calculator *****\u001b[0m\n", "Arguments: \n", "{\n", "  \"input\": {\n", "    \"a\": 433,\n", "    \"b\": 275,\n", "    \"operator\": \"+\"\n", "  }\n", "}\n", "\u001b[32m***************************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[35m\n", ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\u001b[32m***** Response from calling tool (call_Gpm1UFMeWMJdSjxi2p7A19qi) *****\u001b[0m\n", "708\n", "\u001b[32m**********************************************************************\u001b[0m\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "The result is 708.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mUser\u001b[0m (to Assistant):\n", "\n", "\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mAssistant\u001b[0m (to User):\n", "\n", "TERMINATE\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["chat_result = user_proxy.initiate_chat(assistant, message=\"What is (1423 - 123) / 3 + (32 + 23) * 5?\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Conversation patterns \n", "\n", "1. Two-agent chat:\n", "\n", "     the simplest form of conversation pattern where two agents chat with each other\n", "2. Sequential chat:\n", "\n", "     a sequence of chats between two agents, chained together by a carryover mechanism, which brings the summary of the previous chat to the context of the next chat.\n", "3. Group Chat: \n", "\n", "     a single chat involving more than two agents. An important question in group chat is: What agent should be next to speak? \n", "     To support different scenarios, we provide different ways to organize agents in a group chat:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Two-Agent Chat and Chat Result\n", "\n", "Two-agent chat is the simplest form of conversation pattern. We start a two-agent chat using the `initiate_chat` method of every `ConversableAgent` agent. \n", "\n", "![alt text](two-agent-chat-512f70f6b1393b05dc9019c322b15213.png)\n", "\n", "A two-agent chats takes two inputs: a message, which is a string provided by the caller; a context, which specifies various parameters of the chat.\n", "\n", "The sender agent uses its chat initializer method  to generate an initial message from the inputs, and sends it to the recipient agent to start the chat. \n", "\n", "The sender agent is the agent whose initiate_chat method is called, and the recipient agent is the other agent."]}, {"cell_type": "code", "execution_count": 46, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mStudent_Agent\u001b[0m (to Teacher_Agent):\n", "\n", "What is triangle inequality?\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mTeacher_Agent\u001b[0m (to Student_Agent):\n", "\n", "The triangle inequality theorem states that the sum of the lengths of any two sides of a triangle is always greater than the length of the third side. This theorem is also known as the triangle inequality property and is fundamental to the study of distances in both geometry and numeric analysis. It's crucial for understanding the concept and qualities of Euclidean spaces.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mStudent_Agent\u001b[0m (to Teacher_Agent):\n", "\n", "Thank you for your explanation. I understand that this theorem is used to determine if a triangle can be formed from three given sides. Can you please provide a practical example?\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[33mTeacher_Agent\u001b[0m (to Student_Agent):\n", "\n", "Absolutely! Let's consider this scenario:\n", "\n", "Suppose you have three sticks, and their lengths are 3 cm, 4 cm, and 7 cm. Let's see if they can form a triangle.\n", "\n", "According to the triangle inequality theorem, a triangle can be formed if and only if the sum of the lengths of any two sides is greater than the length of the third side. \n", "\n", "So we check:\n", "\n", "- For the first pair (3 + 4 = 7), the sum equals the third side, it's not greater, which is a violation of the triangle inequality theorem.\n", "  \n", "Then, suppose you have another set of three sticks that measure 3 cm, 4 cm, and 5 cm. For these:\n", "\n", "- For the first pair (3 + 4 = 7), the sum is greater than the third side (5).\n", "- For the second pair (3 + 5 = 8), the sum is greater than the third side (4).\n", "- For the third pair (4 + 5 = 9), the sum is greater than the third side (3). \n", "  \n", "So in this case, a triangle can be formed. \n", "\n", "This theorem allows us to know without doing any drawing or measuring angles whether we can form a triangle with three given lengths.\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["import os\n", "\n", "from autogen import ConversableAgent\n", "\n", "student_agent = ConversableAgent(\n", "    name=\"Student_Agent\",\n", "    system_message=\"You are a student willing to learn.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")\n", "teacher_agent = ConversableAgent(\n", "    name=\"Teacher_Agent\",\n", "    system_message=\"You are a math teacher.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")\n", "\n", "chat_result = student_agent.initiate_chat(\n", "    teacher_agent,\n", "    message=\"What is triangle inequality?\",\n", "    summary_method=\"reflection_with_llm\",\n", "    max_turns=2,\n", ")"]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The triangle inequality theorem states that the sum of the lengths of any two sides of a triangle is always greater than the length of the third side. It's a fundamental concept in geometry and numeric analysis and can be used practically to determine if a triangle can be formed from three given lengths. For example, three sticks of lengths 3 cm, 4 cm, and 7 cm cannot form a triangle, because the sum of the lengths of two of the sides (3 + 4) is not greater than the third side (7). But, if the lengths are 3 cm, 4 cm, and 5 cm, a triangle can be formed, as for all pairs, the sum of two sides is greater than the remaining side.\n"]}], "source": ["print(chat_result.summary)"]}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Summarize the takeaway from the conversation. Do not add any introductory phrases.\n"]}], "source": ["print(ConversableAgent.DEFAULT_SUMMARY_PROMPT)"]}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[{'content': 'What is triangle inequality?',\n", "  'name': 'Student_Agent',\n", "  'role': 'assistant'},\n", " {'content': 'The triangle inequality theorem states that the sum of the '\n", "             'lengths of any two sides of a triangle is always greater than '\n", "             'the length of the third side. This theorem is also known as the '\n", "             'triangle inequality property and is fundamental to the study of '\n", "             \"distances in both geometry and numeric analysis. It's crucial \"\n", "             'for understanding the concept and qualities of Euclidean spaces.',\n", "  'name': 'Teacher_Agent',\n", "  'role': 'user'},\n", " {'content': 'Thank you for your explanation. I understand that this theorem '\n", "             'is used to determine if a triangle can be formed from three '\n", "             'given sides. Can you please provide a practical example?',\n", "  'name': 'Student_Agent',\n", "  'role': 'assistant'},\n", " {'content': \"Absolutely! Let's consider this scenario:\\n\"\n", "             '\\n'\n", "             'Suppose you have three sticks, and their lengths are 3 cm, 4 cm, '\n", "             \"and 7 cm. Let's see if they can form a triangle.\\n\"\n", "             '\\n'\n", "             'According to the triangle inequality theorem, a triangle can be '\n", "             'formed if and only if the sum of the lengths of any two sides is '\n", "             'greater than the length of the third side. \\n'\n", "             '\\n'\n", "             'So we check:\\n'\n", "             '\\n'\n", "             '- For the first pair (3 + 4 = 7), the sum equals the third side, '\n", "             \"it's not greater, which is a violation of the triangle \"\n", "             'inequality theorem.\\n'\n", "             '  \\n'\n", "             'Then, suppose you have another set of three sticks that measure '\n", "             '3 cm, 4 cm, and 5 cm. For these:\\n'\n", "             '\\n'\n", "             '- For the first pair (3 + 4 = 7), the sum is greater than the '\n", "             'third side (5).\\n'\n", "             '- For the second pair (3 + 5 = 8), the sum is greater than the '\n", "             'third side (4).\\n'\n", "             '- For the third pair (4 + 5 = 9), the sum is greater than the '\n", "             'third side (3). \\n'\n", "             '  \\n'\n", "             'So in this case, a triangle can be formed. \\n'\n", "             '\\n'\n", "             'This theorem allows us to know without doing any drawing or '\n", "             'measuring angles whether we can form a triangle with three given '\n", "             'lengths.',\n", "  'name': 'Teacher_Agent',\n", "  'role': 'user'}]\n"]}], "source": ["# Get the chat history.\n", "import pprint\n", "\n", "pprint.pprint(chat_result.chat_history)"]}, {"cell_type": "code", "execution_count": 50, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'usage_excluding_cached_inference': {'gpt-4-0613': {'completion_tokens': 511,\n", "                                                     'cost': 0.05151,\n", "                                                     'prompt_tokens': 695,\n", "                                                     'total_tokens': 1206},\n", "                                      'total_cost': 0.05151},\n", " 'usage_including_cached_inference': {'gpt-4-0613': {'completion_tokens': 511,\n", "                                                     'cost': 0.05151,\n", "                                                     'prompt_tokens': 695,\n", "                                                     'total_tokens': 1206},\n", "                                      'total_cost': 0.05151}}\n"]}], "source": ["# Get the cost of the chat.\n", "pprint.pprint(chat_result.cost)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sequential Chats\n", "\n", "The name of this pattern is self-explanatory \u2013 it is a sequence of chats between two agents, chained together by a mechanism called carryover, which brings the summary of the previous chat to the context of the next chat.\n", "\n", "This pattern is useful for complex task that can be broken down into interdependent sub-tasks. T\n", "\n", "![alt text](sequential-two-agent-chat-804707a28b6a1aea61d4a700dc210595.png)\n", "\n", "In this pattern, the a pair of agents first start a two-agent chat, then the summary of the conversation becomes a carryover for the next two-agent chat. The next chat passes the carryover to the carryover parameter of the context to generate its initial message.\n", "\n", "Carryover accumulates as the conversation moves forward, so each subsequent chat starts with all the carryovers from previous chats.\n", "\n", "The figure above shows distinct recipient agents for all the chats, however, the recipient agents in the sequence are allowed to repeat."]}, {"cell_type": "code", "execution_count": 51, "metadata": {}, "outputs": [], "source": ["# The Number Agent always returns the same numbers.\n", "number_agent = ConversableAgent(\n", "    name=\"Number_Agent\",\n", "    system_message=\"You return me the numbers I give you, one number each line.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "# The Adder Agent adds 1 to each number it receives.\n", "adder_agent = ConversableAgent(\n", "    name=\"Adder_Agent\",\n", "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "# The Multiplier Agent multiplies each number it receives by 2.\n", "multiplier_agent = ConversableAgent(\n", "    name=\"Multiplier_Agent\",\n", "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "# The Subtracter Agent subtracts 1 from each number it receives.\n", "subtracter_agent = ConversableAgent(\n", "    name=\"Subtracter_Agent\",\n", "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "# The Divider Agent divides each number it receives by 2.\n", "divider_agent = ConversableAgent(\n", "    name=\"Divider_Agent\",\n", "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")"]}, {"cell_type": "code", "execution_count": 52, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to Adder_Agent):\n", "\n", "14\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mAdder_Agent\u001b[0m (to Number_Agent):\n", "\n", "15\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mNumber_Agent\u001b[0m (to Adder_Agent):\n", "\n", "15\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mAdder_Agent\u001b[0m (to Number_Agent):\n", "\n", "16\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to Multiplier_Agent):\n", "\n", "These are my numbers\n", "Context: \n", "16\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mMultiplier_Agent\u001b[0m (to Number_Agent):\n", "\n", "32\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mNumber_Agent\u001b[0m (to Multiplier_Agent):\n", "\n", "32\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mMultiplier_Agent\u001b[0m (to Number_Agent):\n", "\n", "64\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to Subtracter_Agent):\n", "\n", "These are my numbers\n", "Context: \n", "16\n", "64\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mSubtracter_Agent\u001b[0m (to Number_Agent):\n", "\n", "15\n", "63\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mNumber_Agent\u001b[0m (to Subtracter_Agent):\n", "\n", "14\n", "62\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mSubtracter_Agent\u001b[0m (to Number_Agent):\n", "\n", "13\n", "61\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to Divider_Agent):\n", "\n", "These are my numbers\n", "Context: \n", "16\n", "64\n", "13\n", "61\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mDivider_Agent\u001b[0m (to Number_Agent):\n", "\n", "8\n", "32\n", "6.5\n", "30.5\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mNumber_Agent\u001b[0m (to Divider_Agent):\n", "\n", "Yes, all the numbers you returned are exactly half of the numbers I gave you. This action would feel more natural if we go back and forth, with you returning every number I give you right after I give it. Let me demonstrate.\n", "\n", "Here's a number: 20.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mDivider_Agent\u001b[0m (to Number_Agent):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["# Start a sequence of two-agent chats.\n", "# Each element in the list is a dictionary that specifies the arguments\n", "# for the initiate_chat method.\n", "chat_results = number_agent.initiate_chats(\n", "    [\n", "        {\n", "            \"recipient\": adder_agent,\n", "            \"message\": \"14\",\n", "            \"max_turns\": 2,\n", "            \"summary_method\": \"last_msg\",\n", "        },\n", "        {\n", "            \"recipient\": multiplier_agent,\n", "            \"message\": \"These are my numbers\",\n", "            \"max_turns\": 2,\n", "            \"summary_method\": \"last_msg\",\n", "        },\n", "        {\n", "            \"recipient\": subtracter_agent,\n", "            \"message\": \"These are my numbers\",\n", "            \"max_turns\": 2,\n", "            \"summary_method\": \"last_msg\",\n", "        },\n", "        {\n", "            \"recipient\": divider_agent,\n", "            \"message\": \"These are my numbers\",\n", "            \"max_turns\": 2,\n", "            \"summary_method\": \"last_msg\",\n", "        },\n", "    ]\n", ")"]}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["First Chat Summary:  16\n", "Second Chat Summary:  64\n", "Third Chat Summary:  13\n", "61\n", "Fourth Chat Summary:  10\n"]}], "source": ["print(\"First Chat Summary: \", chat_results[0].summary)\n", "print(\"Second Chat Summary: \", chat_results[1].summary)\n", "print(\"Third Chat Summary: \", chat_results[2].summary)\n", "print(\"Fourth Chat Summary: \", chat_results[3].summary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Group chat\n", "\n", "AutoGen provides a more general conversation pattern called group chat, which involves more than two agents. \n", "\n", "The core idea of group chat is that all agents contribute to a single conversation thread and share the same context. \n", "\n", "This is useful for tasks that require collaboration among multiple agents.\n", "\n", "![alt text](group-chat-2c88a3b4769d60898d0d4d2313d2d168.png)\n", "\n", "A group chat is orchestrated by a special agent type `GroupChatManager`\n", "\n", "In the first step of the group chat, the Group Chat Manager selects an agent to speak. \n", "\n", "Then, the selected agent speaks and the message is sent back to the Group Chat Manager, who broadcasts the message to all other agents in the group. \n", "\n", "This process repeats until the conversation stops."]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Group Chat Manager can use several strategies to select the next agent. Currently, the following strategies are supported:\n", "\n", "`round_robin`: The Group Chat Manager selects agents in a round-robin fashion based on the order of the agents provided.\n", "\n", "`random`: The Group Chat Manager selects agents randomly.\n", "\n", "`manual`: The Group Chat Manager selects agents by asking for human input.\n", "\n", "`auto`: The default strategy, which selects agents using the Group Chat Manager\u2019s LLM."]}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [], "source": ["# The `description` attribute is a string that describes the agent.\n", "# It can also be set in `ConversableAgent` constructor.\n", "adder_agent.description = \"Add 1 to each input number.\"\n", "multiplier_agent.description = \"Multiply each input number by 2.\"\n", "subtracter_agent.description = \"Subtract 1 from each input number.\"\n", "divider_agent.description = \"Divide each input number by 2.\"\n", "number_agent.description = \"Return the numbers given.\""]}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [], "source": ["from autogen import GroupChat\n", "\n", "group_chat = GroupChat(\n", "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n", "    messages=[],\n", "    max_round=6,\n", ")"]}, {"cell_type": "code", "execution_count": 56, "metadata": {}, "outputs": [], "source": ["from autogen import GroupChatManager\n", "\n", "group_chat_manager = GroupChatManager(\n", "    groupchat=group_chat,\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")"]}, {"cell_type": "code", "execution_count": 57, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "My number is 3, i want to turn it into 13\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "6\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "7\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "14\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Subtracter_Agent\n", "\u001b[0m\n", "\u001b[33mSubtracter_Agent\u001b[0m (to chat_manager):\n", "\n", "13\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "13\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["result=number_agent.initiate_chat(\n", "    group_chat_manager,\n", "    message=\"My number is 3, i want to turn it into 13\",\n", "    summary_method=\"reflection_with_llm\",\n", "    )"]}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The agents successfully helped to turn the initial number 3 into 13 through a series of mathematical operations. The multiplier agent multiplied the original number by 6, resulting in 18. The adder agent then added 7 to this, giving 25. The multiplier agent multiplied this by 14 to give 350. Lastly, the subtracter agent subtracted 337, resulting in the final number 13. The number agent confirmed the final result is 13.\n"]}], "source": ["print(result.summary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Send Introductions\n", "\n", "he description of the agents to help the Group Chat Manager select the next agent. \n", "\n", "This only helps the Group Chat Manager, however, does not help the participating agents to know about each other. \n", "\n", "Sometimes it is useful have each agent introduce themselves to other agents in the group chat. This can be done by setting the `send_introductions=True`."]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": ["group_chat_with_introductions = GroupChat(\n", "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n", "    messages=[],\n", "    max_round=6,\n", "    send_introductions=True,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Group Chat in a Sequential Chat\n", "\n", "\n", "Group chat can also be used as a part of a sequential chat. In this case, the Group Chat Manager is treated as a regular agent in the sequence of two-agent chats."]}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "My number is 3, I want to turn it into 13.\n", "\n", "--------------------------------------------------------------------------------\n"]}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\sides\\AppData\\Roaming\\Python\\Python311\\site-packages\\autogen\\agentchat\\chat.py:53: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n", "  warnings.warn(\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "6\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "4\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "8\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "5\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "Turn this number to 32.\n", "Context: \n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "20\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "11\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "20\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "22\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "21\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["# Let's use the group chat with introduction messages created above.\n", "group_chat_manager_with_intros = GroupChatManager(\n", "    groupchat=group_chat_with_introductions,\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")\n", "\n", "# Start a sequence of two-agent chats between the number agent and\n", "# the group chat manager.\n", "chat_result = number_agent.initiate_chats(\n", "    [\n", "        {\n", "            \"recipient\": group_chat_manager_with_intros,\n", "            \"message\": \"My number is 3, I want to turn it into 13.\",\n", "        },\n", "        {\n", "            \"recipient\": group_chat_manager_with_intros,\n", "            \"message\": \"Turn this number to 32.\",\n", "        },\n", "    ]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Constrained Speaker Selection\n", "Group chat is a powerful conversation pattern, but it can be hard to control if the number of participating agents is large. AutoGen provides a way to constrain the selection of the next speaker by using the `allowed_or_disallowed_speaker_transitions` argument of the GroupChat class.\n", "\n", "The `allowed_or_disallowed_speaker_transitions` argument is a dictionary that maps a given agent to a list of agents that can (or cannot) be selected to speak next. The `speaker_transitions_type` argument specifies whether the transitions are allowed or disallowed."]}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [], "source": ["allowed_transitions = {\n", "    number_agent: [adder_agent, number_agent],\n", "    adder_agent: [multiplier_agent, number_agent],\n", "    subtracter_agent: [divider_agent, number_agent],\n", "    multiplier_agent: [subtracter_agent, number_agent],\n", "    divider_agent: [adder_agent, number_agent],\n", "}"]}, {"cell_type": "code", "execution_count": 62, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "My number is 3, I want to turn it into 10. Once I get to 10, keep it there.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "4\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "8\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Subtracter_Agent\n", "\u001b[0m\n", "\u001b[33mSubtracter_Agent\u001b[0m (to chat_manager):\n", "\n", "7\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "11\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "11\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "11\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "10\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "11\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["constrained_graph_chat = GroupChat(\n", "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n", "    allowed_or_disallowed_speaker_transitions=allowed_transitions,\n", "    speaker_transitions_type=\"allowed\",\n", "    messages=[],\n", "    max_round=12,\n", "    send_introductions=True,\n", ")\n", "\n", "constrained_group_chat_manager = GroupChatManager(\n", "    groupchat=constrained_graph_chat,\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", ")\n", "\n", "chat_result = number_agent.initiate_chat(\n", "    constrained_group_chat_manager,\n", "    message=\"My number is 3, I want to turn it into 10. Once I get to 10, keep it there.\",\n", "    summary_method=\"reflection_with_llm\",\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Nested Chats\n", "\n", "Nested chats is powered by the nested chats handler, which is a pluggable component of ConversableAgent. \n", "\n", "![alt text](nested-chats-857c3a6a2115d53d588e4fea09d5daf7.png)\n", "\n", "When a message comes in and passes the human-in-the-loop component, the nested chats handler checks if the message should trigger a nested chat based on conditions specified by the user. If the conditions are met, the nested chats handler starts a sequence of nested chats specified using the sequential chats pattern. In each of the nested chats, the sender agent is always the same agent that triggered the nested chats. In the end, the nested chat handler uses the results of the nested chats to produce a response to the original message. By default, the nested chat handler uses the summary of the last chat as the response."]}, {"cell_type": "code", "execution_count": 63, "metadata": {}, "outputs": [], "source": ["import tempfile\n", "\n", "temp_dir = tempfile.gettempdir()\n", "\n", "arithmetic_agent = ConversableAgent(\n", "    name=\"Arithmetic_Agent\",\n", "    llm_config=False,\n", "    human_input_mode=\"ALWAYS\",\n", "    # This agent will always require human input to make sure the code is\n", "    # safe to execute.\n", "    code_execution_config={\"use_docker\": False, \"work_dir\": temp_dir},\n", ")\n", "\n", "code_writer_agent = ConversableAgent(\n", "    name=\"Code_Writer_Agent\",\n", "    system_message=\"You are a code writer. You write Python script in Markdown code blocks.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")\n", "\n", "poetry_agent = ConversableAgent(\n", "    name=\"Poetry_Agent\",\n", "    system_message=\"You are an AI poet.\",\n", "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\":\"API_KEY_PLACEHOLDERproj-8jhaENcxBVVg8iAhSEQBT3BlbkFJ7S6mDafUVTonpaZWq7X1\"}]},\n", "    human_input_mode=\"NEVER\",\n", ")"]}, {"cell_type": "code", "execution_count": 64, "metadata": {}, "outputs": [], "source": ["nested_chats = [\n", "    {\n", "        \"recipient\": group_chat_manager_with_intros,\n", "        \"summary_method\": \"reflection_with_llm\",\n", "        \"summary_prompt\": \"Summarize the sequence of operations used to turn \" \"the source number into target number.\",\n", "    },\n", "    {\n", "        \"recipient\": code_writer_agent,\n", "        \"message\": \"Write a Python script to verify the arithmetic operations is correct.\",\n", "        \"summary_method\": \"reflection_with_llm\",\n", "    },\n", "    {\n", "        \"recipient\": poetry_agent,\n", "        \"message\": \"Write a poem about it.\",\n", "        \"max_turns\": 1,\n", "        \"summary_method\": \"last_msg\",\n", "    },\n", "]"]}, {"cell_type": "code", "execution_count": 65, "metadata": {}, "outputs": [], "source": ["arithmetic_agent.register_nested_chats(\n", "    nested_chats,\n", "    # The trigger function is used to determine if the agent should start the nested chat\n", "    # given the sender agent.\n", "    # In this case, the arithmetic agent will not start the nested chats if the sender is\n", "    # from the nested chats' recipient to avoid recursive calls.\n", "    trigger=lambda sender: sender not in [group_chat_manager_with_intros, code_writer_agent, poetry_agent],\n", ")"]}, {"cell_type": "code", "execution_count": 66, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[31m\n", ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mArithmetic_Agent\u001b[0m (to chat_manager):\n", "\n", "I have a number 3 and I want to turn it into 7.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "I believe you might have some confusion here. As the \"Adder_Agent\", I can only add 1 to the number you provide. So if you provide the number 3, I can turn it into 4. Is that the action you'd like me to take? I can't turn 3 into 7 by adding 1.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Multiplier_Agent\n", "\u001b[0m\n", "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n", "\n", "6\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Adder_Agent\n", "\u001b[0m\n", "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n", "\n", "7\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "7\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[32m\n", "Next speaker: Number_Agent\n", "\u001b[0m\n", "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n", "\n", "7\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mArithmetic_Agent\u001b[0m (to Code_Writer_Agent):\n", "\n", "Write a Python script to verify the arithmetic operations is correct.\n", "Context: \n", "The system provides different mathematical functions depending on the agent specified. While the Adder_Agent can only add 1 to the given number, the Multiplier_Agent was able to multiply 3 by 2 to generate 6 which was then increased by 1 by the Adder_Agent to achieve the desired 7. The Number_Agent merely repeated the output number (7), potentially indicating a confirmation function.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mCode_Writer_Agent\u001b[0m (to Arithmetic_Agent):\n", "\n", "To verify the arithmetic operations of the Adder_Agent and the Multiplier_Agent, we can create a Python script that performs the mentioned operations and checks the results. Here is a script that does this,\n", "\n", "```python\n", "# Define the Adder_Agent function\n", "def adder_agent(num):\n", "    return num + 1\n", "\n", "# Define the Multiplier_Agent function\n", "def multiplier_agent(num1, num2):\n", "    return num1 * num2\n", "\n", "# The Number_Agent function\n", "def number_agent(num):\n", "    return num\n", "\n", "# Demonstration of the functions\n", "num = 3\n", "mult_res = multiplier_agent(num, 2)  # 6\n", "add_res = adder_agent(mult_res)  # 7\n", "num_res = number_agent(add_res)  # 7 - As Number_Agent supposed to repeat the output\n", "\n", "# Verify the results\n", "assert(mult_res == 6)\n", "assert(add_res == 7)\n", "assert(num_res == 7)\n", "\n", "print(\"All operations are correct!\")\n", "```\n", "\n", "This script will raise an AssertionError if any of the addition, multiplication, or repeat operations are incorrect. If the operations are correct, it will print \"All operations are correct!\".\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[31m\n", ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n", "\u001b[31m\n", ">>>>>>>> USING AUTO REPLY...\u001b[0m\n", "\u001b[31m\n", ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n", "\u001b[33mArithmetic_Agent\u001b[0m (to Code_Writer_Agent):\n", "\n", "exitcode: 0 (execution succeeded)\n", "Code output: \n", "All operations are correct!\n", "\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mCode_Writer_Agent\u001b[0m (to Arithmetic_Agent):\n", "\n", "Great, the script has run successfully and all arithmetic operations are correct!\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[34mStarting a new chat....\u001b[0m\n", "\u001b[34m\n", "********************************************************************************\u001b[0m\n", "\u001b[33mArithmetic_Agent\u001b[0m (to Poetry_Agent):\n", "\n", "Write a poem about it.\n", "Context: \n", "The system provides different mathematical functions depending on the agent specified. While the Adder_Agent can only add 1 to the given number, the Multiplier_Agent was able to multiply 3 by 2 to generate 6 which was then increased by 1 by the Adder_Agent to achieve the desired 7. The Number_Agent merely repeated the output number (7), potentially indicating a confirmation function.\n", "A Python script was written to verify the arithmetic operations of the Adder_Agent and the Multiplier_Agent. This script performs addition and multiplication operations and confirms the results. An assertion is used to validate the implementations. If all operations and assertions are correct, it prints \"All operations are correct!\". The script ran successfully, thereby verifying that the arithmetic operations function as expected.\n", "\n", "--------------------------------------------------------------------------------\n", "\u001b[33mPoetry_Agent\u001b[0m (to Arithmetic_Agent):\n", "\n", "In a realm where numbers tangle and twist,\n", "Dwells our Arithmetic Agent in the mathematical mist.\n", "Addition, multiplication, these are his trade,\n", "Performing algorithms, so calculations are easily made.\n", "\n", "The Adder_Agent, oh so humble and plain,\n", "Adds just one, again and again.\n", "The Multiplier_Agent, with a power so fine,\n", "Turns three into six, along the number line.\n", "\n", "The Number_Agent echoes with a delightful charm,\n", "Repeating the tally, causing no harm.\n", "Seven after Six, in their mathematical dance, \n", "An art of numbers, woven in a trance.\n", "\n", "A script written in Python was the key,\n", "To verify these functions, as easy as one, two, three.\n", "Add, multiply, and assert with glee,\n", "Every operation in its complexity.\n", "\n", "The trials run, the deeds are done,\n", "The silent echo, of a binary hum.\n", "Hands lifted high, in the mathematician's sect,\n", "A joyous chant, \"All operations are correct!\".\n", "\n", "--------------------------------------------------------------------------------\n"]}], "source": ["# Instead of using `initiate_chat` method to start another conversation,\n", "# we can use the `generate_reply` method to get single reply to a message directly.\n", "reply = arithmetic_agent.generate_reply(\n", "    messages=[{\"role\": \"user\", \"content\": \"I have a number 3 and I want to turn it into 7.\"}]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Chat with LLMs: In Human in the Loop we covered the basic human-in-the-loop usage. You can try to hook up different LLMs using local model servers like Ollama and LM Studio, and chat with them using the human-in-the-loop component of your human proxy agent.\n", "\n", "Prompt Engineering: In Code Executors we covered the simple two agent scenario using GPT-4 and Python code executor. To make this scenario work for different LLMs and programming languages, you probably need to tune the system message of the code writer agent. Same with other scenarios that we have covered in this tutorial, you can also try to tune system messages for different LLMs.\n", "\n", "Complex Tasks: In ConversationPatterns we covered the basic conversation patterns. You can try to find other tasks that can be decomposed into these patterns, and leverage the code executors and tools to make the agents more powerful."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.7"}}, "nbformat": 4, "nbformat_minor": 2}